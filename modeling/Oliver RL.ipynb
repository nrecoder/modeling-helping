{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1716da-d51a-47e2-9cac-0e4a22351738",
   "metadata": {},
   "source": [
    "# Environment Wrapper for Farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08182450-30c8-4370-89b8-ec06ecd4ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from mcts import MCTS\n",
    "from agents import * \n",
    "\n",
    "import farmgame \n",
    "\n",
    "# Define the FarmEnv class\n",
    "class FarmEnv:\n",
    "    def __init__(self, farm: Farm, reward_function=None):\n",
    "        self.game = farm  # Accept a Farm instance directly\n",
    "        self.done = False\n",
    "        self.reward_function = reward_function or self.default_reward\n",
    "\n",
    "    def reset(self):\n",
    "        self.game = configure_game()  # Reset the game\n",
    "        self.done = False\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        current_player = self.game.whose_turn()[\"name\"]\n",
    "        self.game = self.game.take_action(action, inplace=True)  # Apply action\n",
    "        reward = self.reward_function(self.game, current_player)  # Calculate reward\n",
    "        self.done = self.game.is_done()  # Check if game is done\n",
    "        new_state = self.get_state()  # Get the updated state\n",
    "        return new_state, reward, self.done, {}  # Return updated state\n",
    "\n",
    "    def get_state(self):\n",
    "        return tuple(self.game)  # Represent state as a tuple\n",
    "\n",
    "    def render(self):\n",
    "        self.game.print_farm()\n",
    "\n",
    "    def default_reward(self, game, player):\n",
    "        return game.playersDict[player][\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab5597-7954-48d3-8a77-abfc92290323",
   "metadata": {},
   "source": [
    "# Q Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa338a18-97df-4462-98d4-ea859dd7a5fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, actions, learning_rate=0.1, discount_factor=0.99, epsilon=0.1):\n",
    "        self.q_table = {}  # Dictionary to store Q-values\n",
    "        self.actions = actions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((state, action), 0.0)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:  # Explore\n",
    "            return random.choice(self.actions)\n",
    "        else:  # Exploit\n",
    "            q_values = [self.get_q_value(state, a) for a in self.actions]\n",
    "            return self.actions[np.argmax(q_values)]\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        max_q_next = max([self.get_q_value(next_state, a) for a in self.actions], default=0)\n",
    "        td_target = reward + self.discount_factor * max_q_next\n",
    "        td_error = td_target - self.get_q_value(state, action)\n",
    "        new_q_value = self.get_q_value(state, action) + self.learning_rate * td_error\n",
    "        self.q_table[(state, action)] = new_q_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09337cb1-f9ee-4803-9776-c903c95dc8c5",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4f7aba-a149-4b7c-a1f3-bbb0e08b1f75",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_rl_agent_against_self(rl_agent, episodes=1000, reward_function=None):\n",
    "    results = []\n",
    "    for episode in range(episodes):\n",
    "        print(f\"Episode {episode + 1}/{episodes}\")\n",
    "        \n",
    "        # Initialize the environment\n",
    "        config = configure_game()  # Default game configuration\n",
    "        env = FarmEnv(config, reward_function=reward_function)\n",
    "        \n",
    "        # Track rewards for each episode\n",
    "        episode_reward = {\"red\": 0, \"purple\": 0}\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            current_player = env.game.whose_turn()[\"name\"]\n",
    "            legal_actions = env.game.legal_actions()\n",
    "            print(f\"Legal actions for {current_player}: {legal_actions}\")  # Debugging\n",
    "            \n",
    "            # RL agent takes action for both players\n",
    "            action = rl_agent.choose_action(state)\n",
    "            print(f\"{current_player.capitalize()} chooses: {action}\")\n",
    "        \n",
    "            # Step the environment\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode_reward[current_player] += reward\n",
    "            print(f\"Reward for action: {reward}\")  # Debugging\n",
    "        \n",
    "            # Update the RL agent\n",
    "            rl_agent.update_q_value(state, action, reward, next_state)\n",
    "        \n",
    "            # Update the RL agent's state to the new state\n",
    "            state = next_state\n",
    "\n",
    "        total_reward = episode_reward[\"red\"] + episode_reward[\"purple\"]\n",
    "        results.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e1b87-6c5b-4528-9f1f-5d3c02690704",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize RL agent and training parameters\n",
    "config = configure_game()\n",
    "env = FarmEnv(config)  # Initialize the environment\n",
    "actions = env.game.legal_actions()  # Pass Action objects directly\n",
    "rl_agent = QLearningAgent(actions=actions)  # Pass the actions to the agent\n",
    "\n",
    "# Define reward function\n",
    "reward_function = lambda game, player: game.playersDict[player][\"score\"]\n",
    "\n",
    "# Train the RL agent against itself\n",
    "training_rewards = train_rl_agent_against_self(\n",
    "    rl_agent=rl_agent,\n",
    "    episodes=1000,\n",
    "    reward_function=reward_function\n",
    ")\n",
    "\n",
    "# Plot training rewards\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"RL Agent Training Rewards Against Itself\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85e8a094-4f62-4749-b386-6f868059928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legal actions for red: ['tomato', 'turnip', 'turnip', 'strawberry', 'strawberry', 'eggplant', 'tomato', 'turnip', 'pillow']\n",
      "red chooses: Tomato00(8,7)\n",
      "Legal actions for purple: ['turnip', 'turnip', 'strawberry', 'strawberry', 'eggplant', 'tomato', 'turnip', 'pillow']\n",
      "purple chooses: Turnip01(13,13)\n",
      "Legal actions for red: ['turnip', 'strawberry', 'strawberry', 'eggplant', 'tomato', 'turnip', 'box', 'pillow']\n",
      "red chooses: Turnip00(12,13)\n",
      "Legal actions for purple: ['strawberry', 'strawberry', 'eggplant', 'tomato', 'turnip', 'box', 'pillow']\n",
      "purple chooses: Strawberry01(8,8)\n",
      "Legal actions for red: ['strawberry', 'eggplant', 'tomato', 'turnip', 'box', 'pillow']\n",
      "red chooses: Strawberry00(7,7)\n",
      "Legal actions for purple: ['eggplant', 'tomato', 'turnip', 'box', 'pillow']\n",
      "purple chooses: Eggplant00(12,14)\n",
      "Legal actions for red: ['tomato', 'turnip', 'box', 'pillow']\n",
      "red chooses: Tomato01(7,8)\n",
      "Legal actions for purple: ['turnip', 'box', 'pillow']\n",
      "purple chooses: Turnip02(13,14)\n",
      "Legal actions for red: ['box', 'pillow']\n",
      "red chooses: redpillow(7,8)\n",
      "Legal actions for purple: ['box', 'pillow']\n",
      "purple chooses: box(16,5)\n"
     ]
    }
   ],
   "source": [
    "#reward_function = lambda game, player: game.playersDict[player][\"score\"]\n",
    "\n",
    "#config = configure_game()  # Default game configuration\n",
    "#env = FarmEnv(config, reward_function=reward_function)\n",
    "\n",
    "#actions = env.game.legal_actions()  # Pass Action objects directly\n",
    "rl_agent = QLearningAgent()  # Pass the actions to the agent\n",
    "\n",
    "# Track rewards for each episode\n",
    "#episode_reward = {\"red\": 0, \"purple\": 0}\n",
    "#state = env.reset()\n",
    "#done = False\n",
    "\n",
    "TheFarm = farmgame.configure_game(layer=\"Items00\",resourceCond=\"even\",costCond=\"low\",visibilityCond=\"full\",redFirst=True)\n",
    "state = TheFarm\n",
    "\n",
    "rl_agent.update(state)\n",
    "#while not done:\n",
    "for i in range(10):\n",
    "    current_player =  state.players[state.turn]#env.game.whose_turn()[\"name\"]\n",
    "    legal_actions = state.legal_actions()#env.game.legal_actions()\n",
    "    print(f\"Legal actions for {current_player['name']}: {[a.name for a in legal_actions]}\")  # Debugging\n",
    "    \n",
    "    rl_agent.update(state)\n",
    "    # RL agent takes action for both players\n",
    "    action = rl_agent.choose_action()\n",
    "    print(f\"{current_player['name']} chooses: {action}\")\n",
    "\n",
    "    # Step the environment\n",
    "    state = state.take_action(action,inplace=True) #pick first veg in list\n",
    "    rwd, done = state.reward(current_player['name'])\n",
    "    #next_state, reward, done, _ = env.step(action)\n",
    "    #episode_reward[current_player] += reward\n",
    "    #print(f\"Reward for action: {reward}\")  # Debugging\n",
    "\n",
    "    # Update the RL agent\n",
    "    rl_agent.update_q_value(action, reward, state)\n",
    "\n",
    "    # Update the RL agent's state to the new state\n",
    "    #state = next_state\n",
    "\n",
    "total_reward = episode_reward[\"red\"] + episode_reward[\"purple\"]\n",
    "#results.append(total_reward)\n",
    "#print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619647d-24cd-4a39-b3fe-b687c0f7c3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
